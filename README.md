# machine_generated_text_detector
Application to detect whether a given text was generated by a machine or written by a human.

## Installation of necessary packages
```bash
pip install -r requirements.txt
```

## Download spacy model to tokenize sentences
```bash
python -m spacy download en_core_web_sm
```

## Download data for training and testing
Data needs to be downloaded from [Google drive](https://drive.google.com/drive/folders/14DulzxuH5TDhXtviRVXsH5e2JTY2POLi) and placed in the data subdirectory as follows:

```
root
|-data
    |-subtask_A
        |-subtaskA_dev_monolingual.jsonl
        |-subtaskA_train_monolingual.jsonl
    |-subtask_B
        |-subtaskB_dev.jsonl
        |-subtaskB_train.jsonl
    |-subtask_C
        |-subtaskC_dev.jsonl
        |-subtaskC_train.jsonl
```

## Run program unit tests
```bash
python run_unit_tests.py
```
## Setting the parameters
In order to set the parameters for training/testing of a specific model You need to adjust the appropriate values in *parameters.yaml* file.
For each given model the set parameters are the same for both training and testing.

## Run training of the selected model
```bash
# Human-Written vs. Machine-Generated Text Classification (Subtask A: Generated text classification)
python train_model.py gtd

# Multi-Way Machine-Generated Text Classification (Subtask B: Model classification)
python train_model.py lmd

# Human-Written vs. Machine-Generated Text Classification (Subtask C: Text separator detection)
python train_model.py tsd
```
### Training on GPU
In order to utilize tensorflows's capabilities on GPU the user might have to install appropriate GPU drivers along with CUDA libraries. 

## Downloading the pretrained model
It is possible to download the pretrained model from the github repository here [GitHub](https://github.com/pmalesa/machine_generated_text_detector), which is located under the *Releases* section of the repository's page. After downloading the model it needs to be placed within the project's directory and the corresponding model name and path variables in *parameters.yaml* file need to be adjusted accordingly. 

## Run testing of the selected model
```bash
# Human-Written vs. Machine-Generated Text Classification (Subtask A: Generated text classification)
python test_model.py gtd

# Multi-Way Machine-Generated Text Classification (Subtask B: Model classification)
python test_model.py lmd

# Human-Written vs. Machine-Generated Text Classification (Subtask C: Text separator detection)
python test_model.py tsd
```

## Prediction of single examples
In order to get a prediction on a single example from the test set run the script below. The provided text example ID must exist in the corresponding .jsonl test dataset.

```bash
python predict.py <model_name> <text_example_id>
```

There is also a possibility to perform predictions on a raw input string as shown below.

```bash
python predict.py <model_name> "Some text to test predictions..."
```

## Evaluation of the trained models
After calling the test_model.py script with the given model the corresponding output file with predictions will be created in the output/<model_name> directory. After that the user can call evaluate the predictions of the given model by running the script below.

```bash
python evaluate_model_results.py <model_name>
```